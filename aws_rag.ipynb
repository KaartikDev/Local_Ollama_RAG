{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97a26b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "# pip install -qU \"langchain[aws]\"\n",
    "# pip install python-dotenv\n",
    "# pip install -qU langchain-aws\n",
    "# pip install -qU langchain-core\n",
    "# ollama pull llama3\n",
    "# pip install langchain-ollama\n",
    "\n",
    "\n",
    "\n",
    "# Investigate:\n",
    "# pip install unstructured\n",
    "# pip install \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a4ddf",
   "metadata": {},
   "source": [
    "### Set Up Credentials and Envitoment Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a620cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "os.environ['AWS_REGION'] = os.getenv('AWS_REGION')\n",
    "\n",
    "import os\n",
    "os.environ['AWS_CA_BUNDLE'] = '/Users/ktejwani/.certs/Zscaler.pem'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93067298",
   "metadata": {},
   "source": [
    "##### Trying to fix certificate issue(Not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfce01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import ssl\n",
    "# import boto3\n",
    "# from botocore.httpsession import URLLib3Session\n",
    "# from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "# # --- START: Force Python to use the Zscaler certificate ---\n",
    "\n",
    "# # 1. Define the path to the certificate that worked with curl\n",
    "# ca_bundle_path = '/Users/ktejwani/.certs/Zscaler.pem'\n",
    "\n",
    "# # 2. Create a custom SSL context that loads your certificate\n",
    "# ssl_context = ssl.create_default_context(cafile=ca_bundle_path)\n",
    "\n",
    "# # 3. Create a botocore session that uses our custom SSL context\n",
    "# http_session = URLLib3Session(ssl_context=ssl_context)\n",
    "# boto_session = boto3.Session(botocore_session=http_session)\n",
    "\n",
    "# # 4. Create the Bedrock client from our custom, secure session\n",
    "# bedrock_client = boto_session.client(\n",
    "#     service_name='bedrock-runtime',\n",
    "#     region_name=os.getenv('AWS_REGION')\n",
    "# )\n",
    "\n",
    "# # --- END: Certificate forcing logic ---\n",
    "\n",
    "\n",
    "# # Initialize BedrockEmbeddings with our custom client.\n",
    "# # This instance is now guaranteed to use the correct certificate.\n",
    "# embeddings = BedrockEmbeddings(\n",
    "#     client=bedrock_client,\n",
    "#     model_id=\"amazon.titan-embed-text-v2:0\"\n",
    "# )\n",
    "\n",
    "# print(\"âœ… Bedrock client initialized successfully with custom SSL certificate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa35536",
   "metadata": {},
   "source": [
    "### Initilaize Gen LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d1b0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_provider=\"bedrock_converse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9997e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95426d6d",
   "metadata": {},
   "source": [
    "### Initialize Embed LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15401be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "# # import boto3\n",
    "# # import os\n",
    "# # session = boto3.Session()\n",
    "# # bedrock_client = session.client(\n",
    "# #     service_name='bedrock-runtime',\n",
    "# #     region_name=os.getenv('AWS_REGION'),\n",
    "# #     verify=False\n",
    "# # )\n",
    "\n",
    "# embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0b567",
   "metadata": {},
   "source": [
    "##### Local work around(NO API Calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d662cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26536777",
   "metadata": {},
   "source": [
    "### In Memory Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4b1aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92a0a6",
   "metadata": {},
   "source": [
    "### Loading PDF Documents from a Directory :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c50ed6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from: data\n",
      "--> Loading tesla 10q.pdf...\n",
      "    ...success!\n",
      "--> Loading nvidia 10q.pdf...\n",
      "    ...success!\n",
      "--> Loading May Apple 10q.pdf...\n",
      "    ...success!\n",
      "\n",
      "Successfully loaded a total of 111 pages from all documents.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Path to your data directory\n",
    "data_directory = \"data\"\n",
    "docs = []\n",
    "\n",
    "print(f\"Loading documents from: {data_directory}\")\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        print(f\"--> Loading {filename}...\")\n",
    "        try:\n",
    "            # Use PyPDFLoader for each file\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            # Extend the main docs list with the pages from the current PDF\n",
    "            docs.extend(loader.load())\n",
    "            print(f\"    ...success!\")\n",
    "        except Exception as e:\n",
    "            # If a file fails to load, print an error and continue\n",
    "            print(f\"    ...ERROR loading {filename}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded a total of {len(docs)} pages from all documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15459c29",
   "metadata": {},
   "source": [
    "### Splitting documents via character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5617396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split all documents into 469 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Split all documents into {len(all_splits)} sub-documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f821b3c",
   "metadata": {},
   "source": [
    "### Embedding in a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21af347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b0272",
   "metadata": {},
   "source": [
    "##### Again API issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90e215ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "\n",
    "# # N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# # api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# example_messages = prompt.invoke(\n",
    "#     {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    "# ).to_messages()\n",
    "\n",
    "# assert len(example_messages) == 1\n",
    "# print(example_messages[0].content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf67e9",
   "metadata": {},
   "source": [
    "### Prompt Augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7346174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "\n",
      "Question: (question goes here)\n",
      "Context: (context goes here)\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# This is the content of the \"rlm/rag-prompt\" created locally\n",
    "# to avoid the SSL error from hub.pull().\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(RAG_PROMPT_TEMPLATE)\n",
    "\n",
    "# Your example code will now work without a network call\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9fc5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3ecf4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c08b86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c61e18f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='85c0b79d-7943-4174-86a5-a63afc1704a0', metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2025-05-02T06:05:09-04:00', 'title': '0000320193-25-000057', 'author': 'EDGARÂ® Online LLC, a subsidiary of OTC Markets Group', 'subject': 'Form 10-Q filed on 2025-05-02 for the period ending 2025-03-29', 'keywords': '0000320193-25-000057; ; 10-Q', 'moddate': '2025-05-02T06:07:30-04:00', 'source': 'data/May Apple 10q.pdf', 'total_pages': 29, 'page': 23, 'page_label': '24', 'start_index': 1722}, page_content='The Companyâ€™s profit margins vary across its products, services, geographic segments and distribution channels. For example, the gross margins on the\\nCompanyâ€™s products and services vary significantly and can change over time. The Companyâ€™s gross margins are subject to volatility and downward pressuredue to a variety of factors, including: continued industry-wide global product pricing pressures and product pricing actions that the Company may take inresponse to such pressures; increased competition; the Companyâ€™s ability to effectively stimulate demand for certain of its products and services; compressed'), Document(id='2e7b0293-2f82-4754-b4c0-d9822e78a76c', metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2025-05-02T06:05:09-04:00', 'title': '0000320193-25-000057', 'author': 'EDGARÂ® Online LLC, a subsidiary of OTC Markets Group', 'subject': 'Form 10-Q filed on 2025-05-02 for the period ending 2025-03-29', 'keywords': '0000320193-25-000057; ; 10-Q', 'moddate': '2025-05-02T06:07:30-04:00', 'source': 'data/May Apple 10q.pdf', 'total_pages': 29, 'page': 23, 'page_label': '24', 'start_index': 4317}, page_content='Various stakeholders, including governments, regulators, investors, employees, customers and others, have differing expectations about a wide range of social\\nand other issues related to the Companyâ€™s business. The Company makes statements about its values, including the environmental and societal impact of itsbusiness, through various non-financial reports, information provided on the Companyâ€™s website, and in press statements and other communications. TheCompany also pursues environmental and other goals and initiatives that involve risks and uncertainties, require investments, and depend in part on third-party\\nperformance or data that is outside the Companyâ€™s control, and there can be no assurance that the Company will fully achieve all of its goals and initiatives.Efforts by the Company to advance its business and values, or achieve its goals and further its initiatives, or to align with stakeholdersâ€™ expectations, or comply'), Document(id='f4162f39-ada4-44c5-9ce0-95457b901112', metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2025-05-02T06:05:09-04:00', 'title': '0000320193-25-000057', 'author': 'EDGARÂ® Online LLC, a subsidiary of OTC Markets Group', 'subject': 'Form 10-Q filed on 2025-05-02 for the period ending 2025-03-29', 'keywords': '0000320193-25-000057; ; 10-Q', 'moddate': '2025-05-02T06:07:30-04:00', 'source': 'data/May Apple 10q.pdf', 'total_pages': 29, 'page': 23, 'page_label': '24', 'start_index': 939}, page_content='supply of current products and offering of existing services, and delays in production ramps of new products and development of new services.\\nFollowing any interruption to its business, the Company can require substantial recovery time, experience significant expenditures to resume operations, and\\nlose significant sales. Because the Company relies on single or limited sources for the supply and manufacture of many critical components, a businessinterruption affecting such sources would exacerbate any negative consequences to the Company. While the Company maintains insurance coverage for certaintypes of losses, such insurance coverage may be insufficient to cover all losses that may arise.\\nThe Company expects its quarterly net sales and results of operations to fluctuate.\\nThe Companyâ€™s profit margins vary across its products, services, geographic segments and distribution channels. For example, the gross margins on the'), Document(id='de5f9a26-66c4-40ed-89f6-f1b988140703', metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2025-05-02T06:05:09-04:00', 'title': '0000320193-25-000057', 'author': 'EDGARÂ® Online LLC, a subsidiary of OTC Markets Group', 'subject': 'Form 10-Q filed on 2025-05-02 for the period ending 2025-03-29', 'keywords': '0000320193-25-000057; ; 10-Q', 'moddate': '2025-05-02T06:07:30-04:00', 'source': 'data/May Apple 10q.pdf', 'total_pages': 29, 'page': 19, 'page_label': '20', 'start_index': 841}, page_content='Company had manufacturing purchase obligations of $38.4 billion, which were payable within 12 months.\\nState Aid Decision Tax Payable\\nDuring the first six months of 2025, the Company released from escrow â‚¬14.2 billion or $15.4 billion to Ireland in connection with the State Aid Decision, which\\nfully settled the obligation.\\nCapital Return Program\\nIn addition to its contractual cash requirements, the Company has an authorized share repurchase program, under which the remaining availability was $40.8billion as of March 29, 2025. On May 1, 2025, the Company announced the Board of Directors had authorized an additional program to repurchase up to $100billion of the Companyâ€™s common stock. The programs do not obligate the Company to acquire a minimum amount of shares.')]\n",
      "\n",
      "\n",
      "Answer: I don't know. The provided context does not mention revenue or any specific information about which company makes the most revenue.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What company is makes most revmue?\"})\n",
    "\n",
    "print(f\"Context: {result['context']}\\n\\n\")\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf60ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
